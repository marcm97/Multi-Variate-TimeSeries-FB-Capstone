{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Validation using  RandomForestClassifier Classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the ArticularyWordRecognition Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinsind/.local/lib/python3.8/site-packages/sktime/datatypes/_series/_check.py:43: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/Users/dinsind/.local/lib/python3.8/site-packages/sktime/datatypes/_hierarchical/_check.py:50: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/Users/dinsind/.local/lib/python3.8/site-packages/sktime/datatypes/_hierarchical/_check.py:51: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n",
      "/Users/dinsind/.local/lib/python3.8/site-packages/sktime/datatypes/_panel/_check.py:48: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_INDEX_TYPES = (pd.Int64Index, pd.RangeIndex, pd.PeriodIndex, pd.DatetimeIndex)\n",
      "/Users/dinsind/.local/lib/python3.8/site-packages/sktime/datatypes/_panel/_check.py:49: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  VALID_MULTIINDEX_TYPES = (pd.Int64Index, pd.RangeIndex)\n"
     ]
    }
   ],
   "source": [
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sktime.datatypes._panel._convert import from_nested_to_3d_numpy\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from pyts.datasets import load_basic_motions\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= load_UCR_UEA_dataset('ArticularyWordRecognition', split=\"train\", return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test= load_UCR_UEA_dataset('ArticularyWordRecognition', split=\"test\", return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275, 9, 144)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_3d = from_nested_to_3d_numpy(X)\n",
    "X_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 9, 144)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_3d= from_nested_to_3d_numpy(X_test)\n",
    "X_test_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reservoir_features:\n",
    "    '''\n",
    "    creates an object associated with a multivariate dataset\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    def __init__(self,data,num_features):\n",
    "        '''\n",
    "        data: Takes in a multidimensional array (x * y * z) - z>y\n",
    "        Initializes it\n",
    "        x: Timeseries\n",
    "        y: Attributes for a given timeseries observation\n",
    "        z: timestamped observations (features)\n",
    "        \n",
    "        num_features: you must specify the dimension you want to reduce it to\n",
    "        \n",
    "        '''\n",
    "        self.features = []\n",
    "        self.filters_used = []\n",
    "        self.original_data = data.copy()\n",
    "        self.data = data.copy()\n",
    "        self.num_features = num_features\n",
    "        self.x = data.shape[0]\n",
    "        self.y = data.shape[1]\n",
    "        self.z = data.shape[2]\n",
    "        # perform checks \n",
    "        #1. 3d numpy array\n",
    "        #2. Each time series should have same number of observations\n",
    "        #3. num_features should be less than timestamped observations\n",
    "    \n",
    "    def normalize(self):\n",
    "        '''\n",
    "        Each attribute could potentially be on a different scale\n",
    "        modifies the original data and performs a min max normalization\n",
    "        '''\n",
    "        for i in range(self.original_data.shape[0]):\n",
    "            for j in range(self.original_data.shape[1]):\n",
    "                self.data[i][j] = (self.original_data[i][j] - self.original_data[i][j].min())/(self.original_data[i][j].max()-self.original_data[i][j].min())\n",
    "    \n",
    "    \n",
    "    def filters(self,stride_len = [1], num_filters = 1):\n",
    "        '''\n",
    "        stride_len: num of columns to skip after each filter multiplication\n",
    "        num_filters: you can specify the number of filters you need; each filter will be of a differnt size\n",
    "        size of filter = n*m \n",
    "        (n = # of rows = attribute size, \n",
    "        m = # of columns)\n",
    "        '''\n",
    "        #Have error check to make sure stride len is a list and value is <length of attributes\n",
    "        n = self.y\n",
    "        \n",
    "        \n",
    "        #Edge case vals is empty/smaller than num_filters\n",
    "        \n",
    "        for iteration in range(num_filters):\n",
    "            m = self._get_m(stride_len[iteration])\n",
    "            filter_a = np.random.random((n,m))\n",
    "            print(\"filter of size \", str(n), \"*\", str(m), \"was created\\n\")\n",
    "            self.filters_used.append(filter_a)\n",
    "            \n",
    "            temp_features =[]\n",
    "            for i in range(self.x):\n",
    "                temp = []\n",
    "                j = 0\n",
    "                while j + m < self.data.shape[2]:\n",
    "                    temp.append((filter_a*self.data[i,:,j:j+m]).mean())\n",
    "                    j+=stride_len[iteration]\n",
    "                temp_features.append(temp)\n",
    "            self.features.append(temp_features)\n",
    "    \n",
    "    \n",
    "    def _get_m(self,stride_len):\n",
    "        '''\n",
    "        stride_len: \n",
    "        based on stride length,& num_features, we calculate possible filter size \n",
    "        '''\n",
    "        m = self.z -(self.num_features)*stride_len\n",
    "        return m\n",
    "    \n",
    "    \n",
    "    def result_features(self):\n",
    "        '''\n",
    "        if multiple filters were added, takes the average result\n",
    "        '''\n",
    "        ans =[]\n",
    "        for timeseries in range(len(self.features[0])):\n",
    "            temp =[]\n",
    "            for feature in range(len(self.features[0][0])):\n",
    "                val = np.mean([self.features[filter][timeseries][feature] for filter in range(len(self.features))])\n",
    "                temp.append(val)\n",
    "            ans.append(temp)\n",
    "        return ans\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data, num_features, stride_len, num_filters):\n",
    "    data_transformed = reservoir_features(data ,num_features = num_features)\n",
    "    #normalize\n",
    "    data_transformed.normalize()\n",
    "    #create 2 filters\n",
    "    data_transformed.filters(stride_len = stride_len, num_filters = num_filters)\n",
    "    data_transformed = data_transformed.result_features()\n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter of size  9 * 24 was created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed= transform_data(X_3d, 40, [3], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter of size  9 * 24 was created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_transformed=transform_data(X_test_3d, 40, [3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "clf.fit(X_train_transformed, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,  46,   5, ...,  34, 113,   4],\n",
       "       [ 54,  19,   5, ...,  25,  15,   4],\n",
       "       [133,  46,   5, ...,  34, 113,   4],\n",
       "       ...,\n",
       "       [ 89, 102, 105, ...,  87,  80, 130],\n",
       "       [112, 115, 116, ..., 156, 142, 147],\n",
       "       [ 91, 102, 105, ...,  76,  78, 130]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.apply(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinsind/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03045921,        -inf,        -inf, ...,        -inf,\n",
       "               -inf,        -inf],\n",
       "       [-0.38566248,        -inf,        -inf, ..., -3.5065579 ,\n",
       "        -3.5065579 ,        -inf],\n",
       "       [-0.03045921,        -inf,        -inf, ...,        -inf,\n",
       "               -inf,        -inf],\n",
       "       ...,\n",
       "       [       -inf,        -inf,        -inf, ..., -4.60517019,\n",
       "               -inf, -2.40794561],\n",
       "       [       -inf, -3.91202301,        -inf, ...,        -inf,\n",
       "               -inf, -1.51412773],\n",
       "       [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "               -inf, -2.65926004]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_log_proba(X_train_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_train_pred=clf.predict(X_train_transformed)\n",
    "clf_acc_score = accuracy_score(y, clf_train_pred)\n",
    "print(clf_acc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, clf.predict_proba(X_train_transformed), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "train_f1 = f1_score(y, clf_train_pred, average='weighted')\n",
    "train_f2 = f1_score(y, clf_train_pred, average='macro')\n",
    "train_f3 = f1_score(y, clf_train_pred, average='micro')\n",
    "print(train_f1)\n",
    "print(train_f2)\n",
    "print(train_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the Test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_test_pred=clf.predict(X_test_transformed)\n",
    "clf_test_acc_score = accuracy_score(y_test, clf_test_pred)\n",
    "print(clf_test_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9253587962962961"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, clf.predict_proba(X_test_transformed), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4174927888342895\n",
      "0.4174927888342896\n",
      "0.44\n"
     ]
    }
   ],
   "source": [
    "#f1-score:\n",
    "test_f1 = f1_score(y_test, clf_test_pred, average='weighted')\n",
    "test_f2 = f1_score(y_test, clf_test_pred, average='macro')\n",
    "test_f3 = f1_score(y_test, clf_test_pred, average='micro')\n",
    "print(test_f1)\n",
    "print(test_f2)\n",
    "print(test_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the AtrialFibrillation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 2, 640)\n",
      "(15, 2, 640)\n"
     ]
    }
   ],
   "source": [
    "X_AF,y_AF= load_UCR_UEA_dataset('AtrialFibrillation', split=\"train\", return_X_y=True)\n",
    "X_AF_test,y_AF_test= load_UCR_UEA_dataset('AtrialFibrillation', split=\"test\", return_X_y=True)\n",
    "X_AF_3d = from_nested_to_3d_numpy(X_AF)\n",
    "X_AF_3d.shape\n",
    "X_AF_test_3d= from_nested_to_3d_numpy(X_AF_test)\n",
    "X_AF_test_3d.shape\n",
    "\n",
    "print(X_AF_3d.shape)\n",
    "print(X_AF_test_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter of size  2 * 520 was created\n",
      "\n",
      "filter of size  2 * 520 was created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed_AF = transform_data(X_AF_3d, 40, [3], 1)\n",
    "X_test_transformed_AF = transform_data(X_AF_test_3d, 40, [3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_transformed_AF))\n",
    "print(len(X_train_transformed_AF[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf_AF= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "clf_AF.fit(X_train_transformed_AF, y_AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_AF.score(X_train_transformed_AF, y_AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7, 10, ...,  8, 10,  7],\n",
       "       [ 1,  3,  4, ...,  1,  3,  3],\n",
       "       [ 1,  3,  3, ...,  1,  3,  3],\n",
       "       ...,\n",
       "       [ 7, 10, 11, ...,  9, 10, 10],\n",
       "       [ 8, 12, 12, ..., 10, 12, 12],\n",
       "       [ 3,  5,  5, ...,  3,  6,  5]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_AF.apply(X_train_transformed_AF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for Train Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 1.0\n",
      "f1_score:Weighted: 1.0\n",
      "f1_score:macro: 1.0\n",
      "f1_score:micro: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_train_pred_AF=clf_AF.predict(X_train_transformed_AF)\n",
    "clf_acc_score_AF = accuracy_score(y_AF, clf_train_pred_AF)\n",
    "print(\"Accuracy_score:\",clf_acc_score_AF)\n",
    "\n",
    "train_AF_f1 = f1_score(y_AF, clf_train_pred_AF, average='weighted')\n",
    "train_AF_f2 = f1_score(y_AF, clf_train_pred_AF, average='macro')\n",
    "train_AF_f3 = f1_score(y_AF, clf_train_pred_AF, average='micro')\n",
    "print(\"f1_score:Weighted:\",train_f1)\n",
    "print(\"f1_score:macro:\",train_f2)\n",
    "print(\"f1_score:micro:\",train_f3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_AF, clf_AF.predict_proba(X_train_transformed_AF), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy for Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 0.26666666666666666\n",
      "f1_score:Weighted: 0.25071225071225073\n",
      "f1_score:macro: 0.25071225071225073\n",
      "f1_score:micro: 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_test_pred_AF=clf_AF.predict(X_test_transformed_AF)\n",
    "clf_acc_score_test_AF = accuracy_score(y_AF_test, clf_test_pred_AF)\n",
    "print(\"Accuracy_score:\",clf_acc_score_test_AF)\n",
    "\n",
    "# F1-Score:\n",
    "test_AF_f1 = f1_score(y_AF_test, clf_test_pred_AF, average='weighted')\n",
    "test_AF_f2 = f1_score(y_AF_test, clf_test_pred_AF, average='macro')\n",
    "test_AF_f3 = f1_score(y_AF_test, clf_test_pred_AF, average='micro')\n",
    "print(\"f1_score:Weighted:\",test_AF_f1)\n",
    "print(\"f1_score:macro:\",test_AF_f2)\n",
    "print(\"f1_score:micro:\",test_AF_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4066666666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_AF_test, clf_AF.predict_proba(X_test_transformed_AF), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the Cricket dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 6, 1197)\n",
      "(72, 6, 1197)\n"
     ]
    }
   ],
   "source": [
    "X_C,y_C= load_UCR_UEA_dataset('Cricket', split=\"train\", return_X_y=True)\n",
    "X_C_test,y_C_test= load_UCR_UEA_dataset('Cricket', split=\"test\", return_X_y=True)\n",
    "X_C_3d = from_nested_to_3d_numpy(X_C)\n",
    "X_C_3d.shape\n",
    "X_C_test_3d= from_nested_to_3d_numpy(X_C_test)\n",
    "X_C_test_3d.shape\n",
    "\n",
    "print(X_C_3d.shape)\n",
    "print(X_C_test_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter of size  6 * 597 was created\n",
      "\n",
      "filter of size  6 * 597 was created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed_C = transform_data(X_C_3d, 200, [3], 1)\n",
    "X_test_transformed_C = transform_data(X_C_test_3d, 200, [3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf_C= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "clf_C.fit(X_train_transformed_C, y_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_C.score(X_train_transformed_C, y_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34, 42, 31, ..., 25, 24, 44],\n",
       "       [15, 24, 17, ..., 15, 15, 25],\n",
       "       [32, 42, 29, ..., 21, 22, 26],\n",
       "       ...,\n",
       "       [23, 23, 30, ..., 15, 16, 25],\n",
       "       [ 9, 16, 18, ..., 15, 14,  6],\n",
       "       [30, 28, 27, ..., 21, 19, 25]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_C.apply(X_train_transformed_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 1.0\n",
      "f1_score:Weighted: 1.0\n",
      "f1_score:macro: 1.0\n",
      "f1_score:micro: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_train_pred_C=clf_C.predict(X_train_transformed_C)\n",
    "clf_acc_score_C = accuracy_score(y_C, clf_train_pred_C)\n",
    "print(\"Accuracy_score:\",clf_acc_score_C)\n",
    "\n",
    "train_C_f1 = f1_score(y_C, clf_train_pred_C, average='weighted')\n",
    "train_C_f2 = f1_score(y_C, clf_train_pred_C, average='macro')\n",
    "train_C_f3 = f1_score(y_C, clf_train_pred_C, average='micro')\n",
    "print(\"f1_score:Weighted:\",train_C_f1)\n",
    "print(\"f1_score:macro:\",train_C_f2)\n",
    "print(\"f1_score:micro:\",train_C_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_C, clf_C.predict_proba(X_train_transformed_C), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 0.5\n",
      "f1_score:Weighted: 0.4862866708454944\n",
      "f1_score:macro: 0.48628667084549443\n",
      "f1_score:micro: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_test_pred_C=clf_C.predict(X_test_transformed_C)\n",
    "clf_acc_score_test_C = accuracy_score(y_C_test, clf_test_pred_C)\n",
    "print(\"Accuracy_score:\",clf_acc_score_test_C)\n",
    "\n",
    "# F1-Score:\n",
    "test_C_f1 = f1_score(y_C_test, clf_test_pred_C, average='weighted')\n",
    "test_C_f2 = f1_score(y_C_test, clf_test_pred_C, average='macro')\n",
    "test_C_f3 = f1_score(y_C_test, clf_test_pred_C, average='micro')\n",
    "print(\"f1_score:Weighted:\",test_C_f1)\n",
    "print(\"f1_score:macro:\",test_C_f2)\n",
    "print(\"f1_score:micro:\",test_C_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8937289562289562"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_C_test, clf_C.predict_proba(X_test_transformed_C), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the Epilepsy Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 3, 206)\n",
      "(138, 3, 206)\n"
     ]
    }
   ],
   "source": [
    "X_E,y_E= load_UCR_UEA_dataset('Epilepsy', split=\"train\", return_X_y=True)\n",
    "X_E_test,y_E_test= load_UCR_UEA_dataset('Epilepsy', split=\"test\", return_X_y=True)\n",
    "X_E_3d = from_nested_to_3d_numpy(X_E)\n",
    "X_E_3d.shape\n",
    "X_E_test_3d= from_nested_to_3d_numpy(X_E_test)\n",
    "X_E_test_3d.shape\n",
    "\n",
    "print(X_E_3d.shape)\n",
    "print(X_E_test_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter of size  3 * 158 was created\n",
      "\n",
      "filter of size  3 * 158 was created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed_E = transform_data(X_E_3d, 16, [3], 1)\n",
    "X_test_transformed_E = transform_data(X_E_test_3d, 16, [3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf_E= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "clf_E.fit(X_train_transformed_E, y_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_E.score(X_train_transformed_E, y_E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75, 77, 74, ..., 70, 72, 86],\n",
       "       [10,  5, 13, ..., 19,  5, 17],\n",
       "       [18, 16, 24, ..., 19, 19, 21],\n",
       "       ...,\n",
       "       [ 3,  1, 11, ...,  9,  4, 10],\n",
       "       [47, 33, 46, ..., 46, 39, 60],\n",
       "       [47, 50, 60, ..., 64, 53, 60]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_E.apply(X_train_transformed_E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 1.0\n",
      "f1_score:Weighted: 1.0\n",
      "f1_score:macro: 1.0\n",
      "f1_score:micro: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_train_pred_E=clf_E.predict(X_train_transformed_E)\n",
    "clf_acc_score_E = accuracy_score(y_E, clf_train_pred_E)\n",
    "print(\"Accuracy_score:\",clf_acc_score_E)\n",
    "\n",
    "train_E_f1 = f1_score(y_E, clf_train_pred_E, average='weighted')\n",
    "train_E_f2 = f1_score(y_E, clf_train_pred_E, average='macro')\n",
    "train_E_f3 = f1_score(y_E, clf_train_pred_E, average='micro')\n",
    "print(\"f1_score:Weighted:\",train_E_f1)\n",
    "print(\"f1_score:macro:\",train_E_f2)\n",
    "print(\"f1_score:micro:\",train_E_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_E, clf_E.predict_proba(X_train_transformed_E), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for Test Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 0.3333333333333333\n",
      "f1_score:Weighted: 0.3312358186822363\n",
      "f1_score:macro: 0.332110143377749\n",
      "f1_score:micro: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_test_pred_E=clf_E.predict(X_test_transformed_E)\n",
    "clf_acc_score_test_E = accuracy_score(y_E_test, clf_test_pred_E)\n",
    "print(\"Accuracy_score:\",clf_acc_score_test_E)\n",
    "\n",
    "# F1-Score:\n",
    "test_E_f1 = f1_score(y_E_test, clf_test_pred_E, average='weighted')\n",
    "test_E_f2 = f1_score(y_E_test, clf_test_pred_E, average='macro')\n",
    "test_E_f3 = f1_score(y_E_test, clf_test_pred_E, average='micro')\n",
    "print(\"f1_score:Weighted:\",test_E_f1)\n",
    "print(\"f1_score:macro:\",test_E_f2)\n",
    "print(\"f1_score:micro:\",test_E_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5946577831051114"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_E_test, clf_E.predict_proba(X_test_transformed_E), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the FingerMovements Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 28, 50)\n",
      "(208, 28, 50)\n"
     ]
    }
   ],
   "source": [
    "X_F,y_F= load_UCR_UEA_dataset('FingerMovements',return_X_y=True)\n",
    "X_F_Train,X_F_test,y_F_Train,y_F_test= train_test_split(X_F,y_F, test_size=0.5, random_state=0)\n",
    "X_F_3d = from_nested_to_3d_numpy(X_F_Train)\n",
    "X_F_3d.shape\n",
    "X_F_test_3d= from_nested_to_3d_numpy(X_F_test)\n",
    "X_F_test_3d.shape\n",
    "\n",
    "print(X_F_3d.shape)\n",
    "print(X_F_test_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter of size  28 * 2 was created\n",
      "\n",
      "filter of size  28 * 2 was created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed_F = transform_data(X_F_3d, 16, [3], 1)\n",
    "X_test_transformed_F = transform_data(X_F_test_3d, 16, [3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf_F= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "clf_F.fit(X_train_transformed_F, y_F_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_F.score(X_train_transformed_F, y_F_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 13,  6, ...,  1,  4, 13],\n",
       "       [50, 68, 83, ..., 61, 65, 66],\n",
       "       [48, 65, 92, ..., 59, 60, 75],\n",
       "       ...,\n",
       "       [36, 65, 64, ..., 30, 60, 33],\n",
       "       [19, 42, 36, ..., 24, 45, 14],\n",
       "       [50, 57, 60, ..., 45, 46, 48]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_F.apply(X_train_transformed_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for Train Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 1.0\n",
      "f1_score:Weighted: 1.0\n",
      "f1_score:macro: 1.0\n",
      "f1_score:micro: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_train_pred_F=clf_F.predict(X_train_transformed_F)\n",
    "clf_acc_score_F = accuracy_score(y_F_Train, clf_train_pred_F)\n",
    "print(\"Accuracy_score:\",clf_acc_score_F)\n",
    "\n",
    "train_F_f1 = f1_score(y_F_Train, clf_train_pred_F, average='weighted')\n",
    "train_F_f2 = f1_score(y_F_Train, clf_train_pred_F, average='macro')\n",
    "train_F_f3 = f1_score(y_F_Train, clf_train_pred_F, average='micro')\n",
    "print(\"f1_score:Weighted:\",train_F_f1)\n",
    "print(\"f1_score:macro:\",train_F_f2)\n",
    "print(\"f1_score:micro:\",train_F_f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for Test Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 0.4951923076923077\n",
      "f1_score:Weighted: 0.4884001134001134\n",
      "f1_score:macro: 0.48894348894348894\n",
      "f1_score:micro: 0.4951923076923077\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_test_pred_F=clf_F.predict(X_test_transformed_F)\n",
    "clf_acc_score_test_F = accuracy_score(y_F_test, clf_test_pred_F)\n",
    "print(\"Accuracy_score:\",clf_acc_score_test_F)\n",
    "\n",
    "# F1-Score:\n",
    "test_F_f1 = f1_score(y_F_test, clf_test_pred_F, average='weighted')\n",
    "test_F_f2 = f1_score(y_F_test, clf_test_pred_F, average='macro')\n",
    "test_F_f3 = f1_score(y_F_test, clf_test_pred_F, average='micro')\n",
    "print(\"f1_score:Weighted:\",test_F_f1)\n",
    "print(\"f1_score:macro:\",test_F_f2)\n",
    "print(\"f1_score:micro:\",test_F_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48312528895053164"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_F_test, clf_F.predict_proba(X_test_transformed_F)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the Handwriting Data Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3, 152)\n",
      "(500, 3, 152)\n"
     ]
    }
   ],
   "source": [
    "X_H,y_H= load_UCR_UEA_dataset('Handwriting', return_X_y=True)\n",
    "X_H_Train,X_H_test,y_H_Train,y_H_test= train_test_split(X_H,y_H, test_size=0.5, random_state=0)\n",
    "X_H_3d = from_nested_to_3d_numpy(X_H_Train)\n",
    "X_H_3d.shape\n",
    "X_H_test_3d= from_nested_to_3d_numpy(X_H_test)\n",
    "X_H_test_3d.shape\n",
    "\n",
    "print(X_H_3d.shape)\n",
    "print(X_H_test_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter of size  3 * 122 was created\n",
      "\n",
      "filter of size  3 * 122 was created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed_H = transform_data(X_H_3d, 10, [3], 1)\n",
    "X_test_transformed_H = transform_data(X_H_test_3d, 10, [3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf_H= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "clf_H.fit(X_train_transformed_H, y_H_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_H.score(X_train_transformed_H, y_H_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95,  81,  82, ...,  85,  73,  86],\n",
       "       [118,  94, 123, ..., 122, 136, 109],\n",
       "       [376, 378, 379, ..., 374, 387, 332],\n",
       "       ...,\n",
       "       [ 86,  78,  77, ...,  69, 119,  57],\n",
       "       [ 65,  45,  62, ...,  69,  42,  45],\n",
       "       [128, 116, 129, ..., 115, 138, 117]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_H.apply(X_train_transformed_H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 1.0\n",
      "f1_score:Weighted: 1.0\n",
      "f1_score:macro: 1.0\n",
      "f1_score:micro: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_train_pred_H=clf_H.predict(X_train_transformed_H)\n",
    "clf_acc_score_H = accuracy_score(y_H_Train, clf_train_pred_H)\n",
    "print(\"Accuracy_score:\",clf_acc_score_H)\n",
    "\n",
    "train_H_f1 = f1_score(y_H_Train, clf_train_pred_H, average='weighted')\n",
    "train_H_f2 = f1_score(y_H_Train, clf_train_pred_H, average='macro')\n",
    "train_H_f3 = f1_score(y_H_Train, clf_train_pred_H, average='micro')\n",
    "print(\"f1_score:Weighted:\",train_H_f1)\n",
    "print(\"f1_score:macro:\",train_H_f2)\n",
    "print(\"f1_score:micro:\",train_H_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_H_Train, clf_H.predict_proba(X_train_transformed_H), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 0.052\n",
      "f1_score:Weighted: 0.049421875331133965\n",
      "f1_score:macro: 0.04969125433543538\n",
      "f1_score:micro: 0.052\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_test_pred_H=clf_H.predict(X_test_transformed_H)\n",
    "clf_acc_score_test_H = accuracy_score(y_H_test, clf_test_pred_H)\n",
    "print(\"Accuracy_score:\",clf_acc_score_test_H)\n",
    "\n",
    "# F1-Score:\n",
    "test_H_f1 = f1_score(y_H_test, clf_test_pred_H, average='weighted')\n",
    "test_H_f2 = f1_score(y_H_test, clf_test_pred_H, average='macro')\n",
    "test_H_f3 = f1_score(y_H_test, clf_test_pred_H, average='micro')\n",
    "print(\"f1_score:Weighted:\",test_H_f1)\n",
    "print(\"f1_score:macro:\",test_H_f2)\n",
    "print(\"f1_score:micro:\",test_H_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5380957279475314"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_H_test, clf_H.predict_proba(X_test_transformed_H), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Basic Motions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 6, 100)\n",
      "(40, 6, 100)\n"
     ]
    }
   ],
   "source": [
    "X_B, X_B_test, y_B, y_B_test = load_basic_motions(return_X_y=True)\n",
    "\n",
    "\n",
    "print(X_B.shape)\n",
    "print(X_B_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter of size  6 * 52 was created\n",
      "\n",
      "filter of size  6 * 52 was created\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_transformed_B = transform_data(X_B, 16, [3], 1)\n",
    "X_test_transformed_B = transform_data(X_B_test, 16, [3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf_B= RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "clf_B.fit(X_train_transformed_B, y_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_B.score(X_train_transformed_B, y_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for Train Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 1.0\n",
      "f1_score:Weighted: 1.0\n",
      "f1_score:macro: 1.0\n",
      "f1_score:micro: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_train_pred_B=clf_B.predict(X_train_transformed_B)\n",
    "clf_acc_score_B = accuracy_score(y_B, clf_train_pred_B)\n",
    "print(\"Accuracy_score:\",clf_acc_score_B)\n",
    "\n",
    "train_B_f1 = f1_score(y_B, clf_train_pred_B, average='weighted')\n",
    "train_B_f2 = f1_score(y_B, clf_train_pred_B, average='macro')\n",
    "train_B_f3 = f1_score(y_B, clf_train_pred_B, average='micro')\n",
    "print(\"f1_score:Weighted:\",train_B_f1)\n",
    "print(\"f1_score:macro:\",train_B_f2)\n",
    "print(\"f1_score:micro:\",train_B_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_B, clf_B.predict_proba(X_train_transformed_B), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for Test Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 0.325\n",
      "f1_score:Weighted: 0.2909751538783797\n",
      "f1_score:macro: 0.2909751538783797\n",
      "f1_score:micro: 0.325\n"
     ]
    }
   ],
   "source": [
    "# Accuracy:\n",
    "clf_test_pred_B=clf_B.predict(X_test_transformed_B)\n",
    "clf_acc_score_test_B = accuracy_score(y_B_test, clf_test_pred_B)\n",
    "print(\"Accuracy_score:\",clf_acc_score_test_B)\n",
    "\n",
    "# F1-Score:\n",
    "test_B_f1 = f1_score(y_B_test, clf_test_pred_B, average='weighted')\n",
    "test_B_f2 = f1_score(y_B_test, clf_test_pred_B, average='macro')\n",
    "test_B_f3 = f1_score(y_B_test, clf_test_pred_B, average='micro')\n",
    "print(\"f1_score:Weighted:\",test_B_f1)\n",
    "print(\"f1_score:macro:\",test_B_f2)\n",
    "print(\"f1_score:micro:\",test_B_f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_B_test, clf_B.predict_proba(X_test_transformed_B), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
